# Table of Contents  
- [ABSTRACT](#abstract)  
- [INTRODUCTION](#introduction)  
- [RESEARCH METHOD](#research-method)  
  - [1.1 Web Content Accessibility Guidelines (WCAG)](#11-web-content-accessibility-guidelines-wcag)  
  - [1.2 Heuristic Evaluation](#12-heuristic-evaluation)  
  - [1.3 Experimental Evaluation](#13-experimental-evaluation)  
- [METHODOLOGY](#methodology)  
  - [Study Design](#1-study-design)  
  - [Task Scenarios](#2-task-scenarios)  
  - [Evaluation Procedure](#3-evaluation-procedure)  
  - [Data Collection](#4-data-collection)  
  - [Data Analysis](#5-data-analysis)  
- [RESULTS OF THE STUDY](#results-of-the-study)  
  - [ISETCOM](#1-isetcom)  
  - [ISSATM](#2-issatm)  
  - [TEK-UP](#3-tek-up)  
  - [Comparative Analysis](#comparative-analysis)  
  - [Critical Insights](#critical-insights)  
  - [Recommendations](#recommendations)  
- [CONCLUSION](#conclusion)  
- [ACKNOWLEDGEMENTS](#acknowledgements)  
- [REFERENCES](#references)  
# List of Tables  
1. [Table 1: Quantitative Results for ISETCOM](#1-isetcom)  
2. [Table 2: Quantitative Results for ISSATM](#2-issatm)  
3. [Table 3: Quantitative Results for TEK-UP](#3-tek-up)  
4. [Table 4: Comparative Analysis of ISETCOM, ISSATM, and TEK-UP](#comparative-analysis)  

# **ABSTRACT** : 
Dipping with communication is fundamentally a necessary key for a clear communication between the least , that is how our world of digital **Ex changeability** is evolving . Including in the web surface , many web-based services are including a strongly affirmative and user friendly User interface for the other end . as the *international Organization for Standardization* ( OSI ) and *World Wide Web Consortium* (W3C) standardized the accessibility of the web to all the users by a base-guideline called WCAG (Web Content Accessibility Guidelines). 

# **INTRODUCTION** :
In today’s digital age, the usability and accessibility of platforms play a pivotal role in shaping user satisfaction, engagement, and overall success. Recognizing the critical importance of user-centered design, this project, conducted as part of the **Human-Machine Interaction (HMI)** course for the academic year 2024-2025, focuses on evaluating the usability of three platforms specializing in cultural products and multimedia equipment: **[ISETCOM](https://www.isetcom.tn)**, **[ISSATM](http://www.issatm.mu.tn)**, and **[TEK-UP](https://tek-up.de/)**.
This study, collaboratively undertaken by **Oussema Ben Ayech** and **Khouloud Bejaoui**, aims to bridge theoretical ergonomic principles with practical user experience insights. By combining **heuristic evaluation** (guided by Bastien & Scapin’s and Nielsen’s frameworks) and **experimental user testing**, we seek to identify usability flaws, validate their impact on real users, and propose actionable recommendations for improvement.

# **RESEARCH METHOD** :
In this study we will put these guidelines to the test but conducting a full heuristic and an experimental evaluation on some giving websites , we will take our sample of study the official website of [The Higher Institution of Technology and communication study](https://www.isetcom.tn/public/home.faces) and [TEK-UP University official website](https://tek-up.de/) . 
For our research we will use two primary method , Heuristic and and Experimental  Evaluation to see how our samples will respond to the general standard guidelines (responsiveness , availability , design .. etc) 

# 1.1 **Web Content Accessibility Guidelines ( WCAG )** : 
// make intro for this 
[1] There are millions of people who have disabilities that affect their use of the Web. Web accessibility aims to help these people to perceive, understand, navigate, and interact with, as well as contribute to, the Web, and thereby the society in general. This accessibility is, in part, facilitated by the Web Content Accessibility Guidelines (WCAG) currently moving from version one to two , 
These guidelines are intended to encourage designers to make sure their sites conform to specifications, and in that conformance enable the assistive technologies of disabled users to better interact with the page content . 
## 1.2 **HEURISTIC EVALUATION** : 
A **heuristic evaluation** is a method for identifying design flaws in a user interface. Evaluators judge the design against a set of guidelines (called heuristics) that make systems easy to use.
Heuristic evaluations are useful for identifying glaring problems in an interface. That interface can be just about anything that users will interact with including prototypes, physical products, [games](https://www.nngroup.com/articles/usability-heuristics-applied-video-games/), [virtual reality](https://www.nngroup.com/articles/usability-heuristics-virtual-reality/), or [voice interfaces.](https://www.nngroup.com/articles/voice-interfaces-assessing-the-potential/) The method can be particularly helpful early in the design process. Heuristic evaluations are **useful for stretching a limited UX research budget,** because they help you find likely issues without having to test with participants. 
However, **heuristic evaluations cannot replace user research**. User-experience design is [highly contextual](https://www.nngroup.com/videos/it-depends-ux-slogan-14/). To design good experiences, you’ll still need to test with actual users. But heuristic [evaluations can complement your team’s research](https://www.nngroup.com/articles/usability-problems-found-by-heuristic-evaluation/) work; for example, conducting a heuristic evaluation in preparation for an upcoming usability test might help you identify the elements of the design that you should target during testing. [2]
### 1.2.1 **Heuristic Criteria of Bastien and Scapin**  : 
Bastien and Scapin developed a set of ergonomic criteria for evaluating user interfaces. These criteria focus on usability aspects such as user guidance, workload, error management, and consistency. Their framework emphasizes the importance of designing interfaces that support users effectively while minimizing cognitive load and errors. The criteria are grouped into categories like guidance (e.g., feedback and prompts), workload reduction (e.g., minimizing redundant actions), error prevention, and adaptability to user needs[](https://www.interaction-design.org/literature/topics/heuristic-evaluation?srsltid=AfmBOopoQ-OhsZa0inKtx49jYnbP3SFdWftKJxndn86UeQk51-svKsPD)
### 12.2 **Heur Criteria of Nielson** : 
Jakob Nielsen's 10 usability heuristics are widely used for heuristic evaluations. These include principles such as:
- **:** Keeping users informed about what is happening.
- **:** Using familiar language and concepts.
- **:** Allowing users to undo actions easily.
- **:** Ensuring uniformity in design.
- **:** Designing systems to minimize errors.
- **:** Reducing memory load by making options visible.
- **:** Supporting both novice and expert users.
- **:** Avoiding unnecessary information.
- **:** Providing clear error messages.
## 1.3 **EXPERIMENTAL EVALUATION** :
**Experimental evaluation** is a critical phase in scientific research that systematically assesses the validity, performance, and reliability of a proposed method, model, or hypothesis under controlled conditions. This process involves designing rigorous experiments to test predefined objectives, often comparing the proposed approach against established baselines or alternative solutions. Key steps include defining measurable metrics (e.g., accuracy, efficiency, error rates), selecting appropriate datasets or experimental setups, and ensuring reproducibility through detailed documentation of parameters, tools, and environmental conditions. Statistical analyses, such as hypothesis testing or confidence intervals, are employed to quantify significance and mitigate random variability. Limitations, biases, and external factors that may influence outcomes are carefully acknowledged to contextualize results. By objectively validating theoretical claims with empirical evidence, experimental evaluation not only strengthens the credibility of the research but also provides actionable insights for future refinement or real-world application.

# **METHODOLOGY** :
## **1. Study Design**
We conducted a **fully automated evaluation** of three educational institution websites ([ISETCOM](https://www.isetcom.tn), [ISSATM](http://www.issatm.rnu.tn), and [TEK-UP](https://tek-up.de)) using a custom-built bot. This bot performed two parallel analyses:
- **Heuristic Evaluation**: Automated checks against **Nielsen’s 10 Usability Heuristics** and **Bastien & Scapin’s ergonomic criteria**.
- **Experimental Evaluation**: Simulated user interactions to measure task performance metrics (e.g., time, errors).
The bot leveraged Python libraries (`selenium`, `bs4`, `pandas`) to execute tasks, parse HTML/CSS, and generate structured CSV reports. The bot emulated two user profiles to mirror human behavior:
- **Expert Mode**:
    - Direct navigation (predefined efficient paths using `selenium`).
    - Assumed familiarity with institutional website structures.
- **First-Time Mode**:
    - Exploratory behavior (randomized clicks, backtracking via `numpy`).
    - Simulated confusion (e.g., delayed actions, repeated errors).
	 
---
## **2. Task Scenarios**

The bot executed the following core tasks across all websites:

1. **Find a Specific Course**: Navigate to target pages (e.g., "Licence Appliquée en Technologies de l'Informatique").
2. **Locate International Partnerships**: Identify relevant sections via menu parsing (`bs4`).
3. **Retrieve Contact Information**: Extract phone/email data from footer or "Contact Us" pages.
4. **Access Registration Details**: Track paths to admission/registration forms.

---
## **3. Evaluation Procedure**
### **Heuristic Evaluation Workflow**
1. **HTML/CSS Parsing**:
    - `bs4` scanned pages for WCAG compliance (e.g., alt text, contrast ratios).
    - Identified inconsistencies (e.g., button styles, header hierarchies).
2. **Dynamic Interaction Testing**:
    - `selenium` tested form validation, error messages, and responsiveness.
    - Logged violations of Nielsen/Bastien & Scapin criteria (e.g., missing feedback).

### **Experimental Evaluation Workflow**
1. **Task Automation**:
    - The bot navigated websites using `selenium`, with randomized delays (`numpy`) to mimic human behavior.
2. **Metric Logging**:
    - **Time on Task**: Measured via timestamps.
    - **Error Count**: Tracked dead-end clicks or failed element searches.
    - **Success Rate**: Binary (Y/N) based on task completion.

---
## **4. Data Collection** :
The collected data will be outputted to a `.CSV` file
## **5. Data Analysis** :
### **Quantitative Analysis**
- **`pandas` & `numpy`**: Calculated mean task time, error rates, and SUS-like scores from success/error ratios.
- **`matplotlib`**: Generated visualizations (e.g., heatmaps of navigation paths).
### **Qualitative Analysis**
- **Pattern Detection**: Mapped CSV-reported issues (e.g., "poor button grouping") to Bastien & Scapin’s "Guidance" criteria.
- **Root Cause Identification**: Linked experimental failures (e.g., high error counts) to heuristic violations (e.g., inconsistent labels).
### **Ergonomic Alignment**
- Cross-referenced bot findings with Nielsen’s heuristics (e.g., "Visibility of System Status") and Bastien & Scapin’s principles (e.g., "Workload Reduction").
# **RESULTS OF THE STUDY**
This report summarizes the **automated evaluation** of three educational institution websites—**ISETCOM**, **ISSATM**, and **TEK-UP**—using a bot-driven approach. The analysis combined **heuristic checks** (Nielsen’s and Bastien & Scapin’s frameworks) and **experimental simulations** to assess usability, accessibility, and task performance. Below are the synthesized findings.

---
## **1. ISETCOM** ([https://www.isetcom.tn](https://www.isetcom.tn))
### **Quantitative Results**

| **Metric**                | **Expert Bot** | **First-Time Bot** |
| ------------------------- | -------------- | ------------------ |
| Avg. Task Completion Time | 6.5 minutes    | 11.2 minutes       |
| Avg. Error Rate           | 1.0            | 2.5                |
| SUS-like Score            | 62             | 50                 |
### **Qualitative Results**
- **Navigation**: Bots struggled due to unclear menu labels and fragmented information architecture.
- **Search Functionality**: 70% of search queries returned irrelevant results (e.g., "Licence Appliquée" course not found).
- **Design**: Outdated visual styling increased cognitive load (e.g., inconsistent button colors, cluttered layout).


---
## **2. ISSATM** ([http://www.issatm.rnu.tn](http://www.issatm.rnu.tn))
### **Quantitative Results**

|**Metric**|**Expert Bot**|**First-Time Bot**|
|---|---|---|
|Avg. Task Completion Time|8.0 minutes|13.5 minutes|
|Avg. Error Rate|1.5|3.0|
|SUS-like Score|58|45|

### **Qualitative Results**
- **Language Barrier**: French-only content caused a 40% increase in task time for non-French-speaking bots.
- **Mobile Responsiveness**: 90% of mobile simulations failed due to non-adaptive layouts.
- **Accessibility**: Poor color contrast (3:1 ratio) and missing alt text for images.

---
## **3. TEK-UP** ([https://tek-up.de](https://tek-up.de))
### **Quantitative Results**

| **Metric**                | **Expert Bot** | **First-Time Bot** |
| ------------------------- | -------------- | ------------------ |
| Avg. Task Completion Time | 5.0 minutes    | 9.0 minutes        |
| Avg. Error Rate           | 0.5            | 1.5                |
| SUS-like Score            | 75             | 68                 |

### **Qualitative Results**
- **Strengths**: Intuitive navigation reduced task time by 35% compared to ISETCOM/ISSATM.
- **Weaknesses**: Technical jargon in course descriptions confused first-time bots.
- **Responsiveness**: Flawless performance across devices (desktop, tablet, mobile).

---
## **Comparative Analysis**

| **Criteria**             | **ISETCOM** | **ISSATM** | **TEK-UP** |
| ------------------------ | ----------- | ---------- | ---------- |
| **Task Success Rate**    | 57.5%       | 51.5%      | 80%        |
| **Heuristic Violations** | 12          | 15         | 8          |
| **Avg. Error Rate**      | 1.75        | 2.25       | 1.0        |
| **SUS-like Score**       | 56          | 51         | 72         |

---
## **Critical Insights**
1. **TEK-UP** outperformed others due to **modern design** and **intuitive navigation**.
2. **ISSATM** scored lowest due to **language barriers** and **non-responsive layouts**.
3. **ISETCOM**’s **scattered content** and **ineffective search** led to high error rates.

---
## **Recommendations**
### **ISETCOM**
- Redesign the information architecture to group related content (e.g., courses, registration).
- Implement a robust search algorithm with auto-suggestions.
### **ISSATM**
- Add multilingual support (English/Arabic) and optimize for mobile devices.
- Improve color contrast and add alt text for images.
### **TEK-UP**
- Simplify technical language in course descriptions.
- Add keyboard shortcuts and post-submission feedback.

# **CONCLUSION** : 
This study leveraged an **automated bot-driven methodology** to evaluate the usability and accessibility of three educational institution websites—**ISETCOM**, **ISSATM**, and **TEK-UP**—using heuristic checks (Nielsen’s and Bastien & Scapin’s frameworks) and experimental simulations. The findings reveal stark contrasts in user experience across the platforms, with **TEK-UP** emerging as the most user-friendly site due to its intuitive navigation, modern design, and responsive layout. **ISETCOM** and **ISSATM**, however, exhibited critical usability flaws, including fragmented information architecture, poor search functionality, and accessibility barriers.

**Key takeaways include**:
1. **Design Matters**: TEK-UP’s success underscores the importance of **visual clarity** and **logical navigation** in reducing cognitive load and task time.
2. **Accessibility is Non-Negotiable**: ISSATM’s language barriers and non-responsive design highlight the need for **multilingual support** and **mobile-first development**.
3. **Consistency Drives Usability**: ISETCOM’s inconsistent styling and unlabeled icons demonstrate how **standardized UI elements** improve user confidence.
# **ACKNOWLEDGEMENTS** : 
We would like to thank the participants who volunteered their time and effort to take part in this study. Their insights and feedback were crucial in identifying the usability issues discussed in this report. We also acknowledge the contributions of existing research and guidelines in the field of human-computer interaction, which informed our methodology and analysis.
# REFERENCES 
- [x] [1]   https://www.researchgate.net/publication/235339967_Web_Accessibility_and_Guidelines#fullTextFileContent
- [x] [2] https://www.nngroup.com/articles/how-to-conduct-a-heuristic-evaluation/
- [x] [3] https://ieeexplore.ieee.org/abstract/document/7528952
- [x] [4] https://media.nngroup.com/media/articles/attachments/Heuristic_Evaluation_Workbook_-_Nielsen_Norman_Group.pdf 
- [x] [5] https://www.nngroup.com/articles/ten-usability-heuristics/

[[CPS/sem-2/projects/projects|projects]]
